"""Unit tests for extraction utilities."""

from vivarium_profiling.tools.extraction import (
    ExtractionConfig,
    FunctionCallConfiguration,
    bottleneck_config,
    extract_runtime,
    parse_function_metrics,
    phase_config,
)


class TestFunctionCallConfiguration:
    """Tests for FunctionCallConfiguration dataclass."""

    def test_function_call_configuration_defaults(self):
        """Test FunctionCallConfiguration with default extraction flags."""
        pattern = FunctionCallConfiguration(
            name="test_func", filename="test.py", function_name="test_func"
        )

        assert pattern.name == "test_func"
        assert pattern.filename == "test.py"
        assert pattern.function_name == "test_func"
        assert pattern.pattern == r"test\.py:\d+\(test_func\)"
        assert pattern.extract_cumtime is True
        assert pattern.extract_percall is False
        assert pattern.extract_ncalls is False
        assert pattern.cumtime_col == "test_func_cumtime"
        assert pattern.percall_col == "test_func_percall"
        assert pattern.ncalls_col == "test_func_ncalls"
        assert pattern.columns == ["test_func_cumtime"]

    def test_function_call_configuration_all_extracts(self):
        """Test FunctionCallConfiguration with all extraction flags enabled."""
        pattern = FunctionCallConfiguration(
            name="bottleneck",
            filename="test.py",
            function_name="bottleneck",
            extract_cumtime=True,
            extract_percall=True,
            extract_ncalls=True,
        )

        assert pattern.pattern == r"test\.py:\d+\(bottleneck\)"
        assert pattern.columns == [
            "bottleneck_cumtime",
            "bottleneck_percall",
            "bottleneck_ncalls",
        ]

    def test_function_call_configuration_custom_templates(self):
        """Test FunctionCallConfiguration with custom column templates."""
        pattern = FunctionCallConfiguration(
            name="phase",
            filename="engine.py",
            function_name="phase",
            cumtime_template="rt_{name}_s",
        )

        assert pattern.pattern == r"engine\.py:\d+\(phase\)"
        assert pattern.cumtime_col == "rt_phase_s"
        assert pattern.columns == ["rt_phase_s"]


class TestExtractionConfig:
    """Tests for ExtractionConfig class."""

    def test_extraction_config_defaults(self):
        """Test ExtractionConfig with default patterns."""
        config = ExtractionConfig()

        assert len(config.patterns) > 0
        assert len(config.metric_names) > 0
        assert len(config.metric_columns) > 0
        assert len(config.results_columns) > 4  # base + metrics

    def test_extraction_config_custom_patterns(self):
        """Test ExtractionConfig with custom patterns."""
        patterns = [
            FunctionCallConfiguration("func1", "test.py", "func1"),
            bottleneck_config("func2", "test.py", "func2"),
        ]
        config = ExtractionConfig(patterns=patterns)

        assert len(config.patterns) == 2
        assert config.metric_names == ["func1", "func2"]  # Only func2 has all extracts

    def test_metric_columns(self):
        """Test metric_columns property."""
        patterns = [
            FunctionCallConfiguration(
                "a", "test.py", "a", extract_cumtime=True, extract_percall=True
            ),
            FunctionCallConfiguration("b", "test.py", "b", extract_cumtime=True),
        ]
        config = ExtractionConfig(patterns=patterns)

        assert config.metric_columns == ["a_cumtime", "a_percall", "b_cumtime"]

    def test_results_columns(self):
        """Test results_columns includes base columns."""
        patterns = [FunctionCallConfiguration("test", "test.py", "test")]
        config = ExtractionConfig(patterns=patterns)

        cols = config.results_columns
        assert cols[:4] == ["model_spec", "run", "rt_s", "mem_mb"]
        assert "test_cumtime" in cols


class TestParseMetrics:
    """Tests for metric parsing functions."""

    def test_parse_function_metrics_basic(self, sample_stats_file):
        """Test parsing basic function metrics."""
        cumtime, percall, ncalls = parse_function_metrics(
            sample_stats_file, r"results/manager\.py:\d+\(gather_results\)"
        )

        assert cumtime == 2.500
        assert percall == 0.016
        assert ncalls == 160

    def test_parse_function_metrics_recursive_calls(self, sample_stats_file):
        """Test parsing function with recursive calls (format: 50/25)."""
        cumtime, percall, ncalls = parse_function_metrics(
            sample_stats_file, r"some/custom/module\.py:\d+\(custom_function\)"
        )

        assert cumtime == 0.600
        assert percall == 0.024
        assert ncalls == 25  # Should extract the primitive call count

    def test_extract_runtime(self, sample_stats_file):
        """Test extracting total runtime from stats file."""
        runtime = extract_runtime(sample_stats_file)

        assert runtime == 10.500

    def test_parse_function_metrics_not_found(self, sample_stats_file):
        """Test parsing when function is not found."""
        cumtime, percall, ncalls = parse_function_metrics(
            sample_stats_file, r"nonexistent\.py:\d+\(missing\)"
        )

        assert cumtime is None
        assert percall is None
        assert ncalls is None

    def test_parsing_invalid_file(self, tmp_path):
        """Test parsing with invalid file path."""
        cumtime, percall, ncalls = parse_function_metrics(
            tmp_path / "nonexistent.txt", r"pattern"
        )

        assert cumtime is None
        assert percall is None
        assert ncalls is None

        runtime = extract_runtime(tmp_path / "nonexistent.txt")

        assert runtime is None


class TestExtractionConfigExtract:
    """Tests for ExtractionConfig.extract_metrics method."""

    def test_extract_metrics_default_patterns(self, sample_stats_file):
        """Test extracting metrics with default patterns."""
        config = ExtractionConfig()
        metrics = config.extract_metrics(sample_stats_file)

        # default phase metrics
        assert metrics["rt_setup_s"] == 8.000
        assert metrics["rt_initialize_simulants_s"] == 2.000
        assert metrics["rt_run_s"] == 5.000
        assert metrics["rt_finalize_s"] == 0.300
        assert metrics["rt_report_s"] == 0.100

        # default bottleneck metrics
        assert metrics["gather_results_cumtime"] == 2.500
        assert metrics["pipeline_call_cumtime"] == 1.200
        assert metrics["population_get_cumtime"] == 0.800

    def test_extract_metrics_custom_patterns(self, sample_stats_file):
        """Test extracting metrics with custom patterns."""
        patterns = [
            FunctionCallConfiguration(
                "custom_func",
                "some/custom/module.py",
                "custom_function",
                extract_cumtime=True,
                extract_ncalls=True,
                extract_percall=False,
            ),
            phase_config("initialize_simulants"),
        ]
        config = ExtractionConfig(patterns=patterns)
        metrics = config.extract_metrics(sample_stats_file)

        assert metrics["custom_func_cumtime"] == 0.600
        assert metrics["custom_func_ncalls"] == 25  # Primitive calls
        assert "custom_func_percall" not in metrics  # Not extracted

        assert metrics["rt_initialize_simulants_s"] == 2.000

    def test_extract_metrics_missing_patterns(self, sample_stats_file):
        """Test extracting metrics when patterns don't match."""
        patterns = [FunctionCallConfiguration("missing", "nonexistent.py", "missing")]
        config = ExtractionConfig(patterns=patterns)
        metrics = config.extract_metrics(sample_stats_file)

        assert metrics["missing_cumtime"] is None
